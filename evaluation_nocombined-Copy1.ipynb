{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys, os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import csv, yaml\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(\"./python\")\n",
    "\n",
    "from models.allModels import *\n",
    "import easydict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"config\" : 'config_even_eval.yaml',\n",
    "    \"output\" : 'test1592',\n",
    "  \n",
    "    \"device\" : 0,\n",
    "    \"epoch\" : 1,\n",
    "    \"batch\" : 10000000,\n",
    "    \"lr\" : 0.0001,\n",
    "    \"seed\" : 12345,\n",
    "    \"kernel_size\" : 11,\n",
    "    \"model\" : '1DCNN3FC2',\n",
    "    \"ratio\" : 1.0,\n",
    "    \"runnum\" : 1592,\n",
    "    \"rho\" : 1.4,\n",
    "    \"vtz\" : 1.0,\n",
    "    \"odd\" : 1,\n",
    "    \"minvalue\" : 400,\n",
    "    \"dvertex\" : 1,\n",
    "  \n",
    "   \n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/store/hep/users/yewzzang/JSNS2/com_data/r001592/ME_cut_even_Rho_1.4_ZL_1.0_noDIN/*.h5\n",
      "/store/hep/users/yewzzang/JSNS2/com_data/r001592/FN_cut_even_Rho_1.4_ZL_1.0_noDIN/*.h5\n",
      "     procName                                           fileName  weight  \\\n",
      "0          ME  /store/hep/users/yewzzang/JSNS2/com_data/r0015...     1.0   \n",
      "1          ME  /store/hep/users/yewzzang/JSNS2/com_data/r0015...     1.0   \n",
      "2          ME  /store/hep/users/yewzzang/JSNS2/com_data/r0015...     1.0   \n",
      "3          ME  /store/hep/users/yewzzang/JSNS2/com_data/r0015...     1.0   \n",
      "4          ME  /store/hep/users/yewzzang/JSNS2/com_data/r0015...     1.0   \n",
      "...       ...                                                ...     ...   \n",
      "6004       FN  /store/hep/users/yewzzang/JSNS2/com_data/r0015...     1.0   \n",
      "6005       FN  /store/hep/users/yewzzang/JSNS2/com_data/r0015...     1.0   \n",
      "6006       FN  /store/hep/users/yewzzang/JSNS2/com_data/r0015...     1.0   \n",
      "6007       FN  /store/hep/users/yewzzang/JSNS2/com_data/r0015...     1.0   \n",
      "6008       FN  /store/hep/users/yewzzang/JSNS2/com_data/r0015...     1.0   \n",
      "\n",
      "     label fileIdx  nEvents  \n",
      "0        1       0      0.0  \n",
      "1        1       1      0.0  \n",
      "2        1       2      0.0  \n",
      "3        1       3      0.0  \n",
      "4        1       4      0.0  \n",
      "...    ...     ...      ...  \n",
      "6004     0    6004      0.0  \n",
      "6005     0    6005      0.0  \n",
      "6006     0    6006      0.0  \n",
      "6007     0    6007      0.0  \n",
      "6008     0    6008      0.0  \n",
      "\n",
      "[6009 rows x 6 columns] SI\n",
      "--------------------------------------------------------------------------------\n",
      "Label=1 sumE=253585, sumW=253585\n",
      "Label=0 sumE=9100, sumW=9100\n",
      "Label with maxSumE:1\n",
      "      maxWeight=1 minWeight=1 avgWeight=1\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = yaml.load(open(args.config).read(), Loader=yaml.FullLoader)\n",
    "config['training']['learningRate'] = float(config['training']['learningRate'])\n",
    "if args.seed: config['training']['randomSeed1'] = args.seed\n",
    "if args.epoch: config['training']['epoch'] = args.epoch\n",
    "if args.lr: config['training']['learningRate'] = args.lr\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "if torch.cuda.is_available() and args.device >= 0: torch.cuda.set_device(args.device)\n",
    "if not os.path.exists('result/' + args.output): os.makedirs('result/' + args.output)\n",
    "\n",
    "##### Define dataset instance #####\n",
    "from dataset.WFCh2Dataset_each_norm_involve_raw import *\n",
    "\n",
    "##### Define dataset instance #####\n",
    "dset = WFCh2Dataset_each_norm_involve_raw(channel=config['format']['channel'], output = 'result/' + args.output)\n",
    "for sampleInfo in config['samples']:\n",
    "    if 'ignore' in sampleInfo and sampleInfo['ignore']: continue\n",
    "    name = sampleInfo['name']\n",
    "    if args.odd == 1:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_even_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'_noDIN/*.h5'\n",
    "    elif args.odd == 2:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_odd_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'_noDIN/*.h5'\n",
    "    \n",
    "    else: ## total training\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'_noDIN/*.h5'\n",
    "    print(in_path)\n",
    "\n",
    "    dset.addSample(name, in_path, weight=sampleInfo['xsec']/sampleInfo['ngen'])\n",
    "    dset.setProcessLabel(name, sampleInfo['label'])\n",
    "dset.initialize()\n",
    "\n",
    "lengths = [int(x*len(dset)) for x in config['training']['splitFractions']]\n",
    "lengths.append(len(dset)-sum(lengths))\n",
    "torch.manual_seed(config['training']['randomSeed1'])\n",
    "kwargs = {'num_workers':min(config['training']['nDataLoaders'], os.cpu_count()),\n",
    "          'batch_size':args.batch, 'pin_memory':False}\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "testLoader = DataLoader(dset, **kwargs)\n",
    "\n",
    "\n",
    "torch.manual_seed(torch.initial_seed())\n",
    "\n",
    "##### Define model instance #####\n",
    "from models.allModels import *\n",
    "#model = WF1DCNNModel(nChannel=dset.nCh, nPoint=dset.nPt)\n",
    "model = torch.load('result/test1592/model.pth', map_location='cpu')\n",
    "model.load_state_dict(torch.load('result/test1592/weight.pth', map_location='cpu'))\n",
    "\n",
    "model.fc.add_module('output', torch.nn.Sigmoid())\n",
    "device = 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "labels, preds = [], []\n",
    "weights = []\n",
    "procIdxs = []\n",
    "fileIdxs = []\n",
    "idxs = []\n",
    "model.eval()\n",
    "val_loss, val_acc = 0., 0.\n",
    "# for i, (data, label0, weight, rescale, procIdx, fileIdx, idx, dT, dVertex, vertexX, vertexY, vertexZ) in enumerate(tqdm(testLoader)):\n",
    "\n",
    "# for i, (data, label0, weight, rescale, procIdx, fileIdx, idx) in enumerate(tqdm(testLoader)):\n",
    "for i, (data, label0, weight, rescale, procIdx, fileIdx, idx, dVertexx, minvaluee, pChargee,vertexx,vertexy,vertexz) in enumerate(tqdm(testLoader)):\n",
    "    data = data\n",
    "\n",
    "\n",
    "    label = label0\n",
    "    label0 = label0.reshape(-1)[()].numpy()\n",
    "    rescale = rescale.float()\n",
    "    weight = weight.float()*rescale\n",
    "\n",
    "    pred = model(data)\n",
    "\n",
    "    #weight = np.ones(len(label0))\n",
    "    #weight[label0==1] = dset.classWeight.item()\n",
    "\n",
    "    labels.extend([x.item() for x in label])\n",
    "    weights.extend([x.item() for x in weight])\n",
    "    preds.extend([x.item() for x in pred.view(-1)])\n",
    "    procIdxs.extend([x.item() for x in procIdx])\n",
    "    fileIdxs.extend([x.item() for x in fileIdx])\n",
    "    idxs.extend([x.item() for x in idx])\n",
    "df = pd.DataFrame({'label':labels, 'prediction':preds, 'weight':weights, 'procIdx':procIdxs, 'fileIdx':fileIdxs, 'idx':idxs})\n",
    "\n",
    "fPred = 'result/' + args.output + '/' + args.output + '.csv'\n",
    "df.to_csv(fPred, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##### Draw ROC curve #####\n",
    "si_path = 'result/' + args.output + '/sampleInfo.csv'\n",
    "si = pd.read_csv(si_path)\n",
    "fPred = 'result/' + args.output + '/' + args.output + '.csv'\n",
    "info = pd.read_csv(fPred)\n",
    "\n",
    "info_numpy = np.array(info)\n",
    "si_numpy = np.array(si)\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "dVertexs = []\n",
    "dTs = []\n",
    "vertexXs = []\n",
    "vertexYs = []\n",
    "vertexZs = []\n",
    "for i in range(len(info_numpy)):\n",
    "\n",
    "    label = info_numpy[i][0]\n",
    "    pred = info_numpy[i][1]\n",
    "\n",
    "    fileidx = info_numpy[i][4]\n",
    "    \n",
    "    filename = si_numpy[int(fileidx)][2]\n",
    "    \n",
    "    \n",
    "    idx = info_numpy[i][5]\n",
    "\n",
    "    \n",
    "    data = h5py.File(filename,'r')\n",
    "\n",
    "    dT = data['events']['dT'][idx]\n",
    "    dVertex = data['events']['dVertex'][idx]\n",
    "    vertexX = data['events']['vertexX'][idx]\n",
    "    vertexY = data['events']['vertexY'][idx]\n",
    "    vertexZ = data['events']['vertexZ'][idx]\n",
    "    \n",
    "    \n",
    "    preds.append(pred)\n",
    "    labels.append(label)\n",
    "    dVertexs.append(dVertex)\n",
    "    dTs.append(dT)\n",
    "#     print(dTs.type)\n",
    "    vertexXs.append(vertexX)\n",
    "    vertexYs.append(vertexY)\n",
    "    vertexZs.append(vertexZ)\n",
    "\n",
    "preds = np.array(preds)\n",
    "labels = np.array(labels)\n",
    "dVertexs = np.array(dVertexs)\n",
    "dTs = np.array(dTs)\n",
    "vertexXs = np.array(vertexXs)\n",
    "vertexYs = np.array(vertexYs)\n",
    "vertexZs = np.array(vertexZs)\n",
    "\n",
    "\n",
    "ME_label = []\n",
    "ME_dVertex = []\n",
    "ME_dT = []\n",
    "ME_vertexX = []\n",
    "ME_vertexY = []\n",
    "ME_vertexZ = []\n",
    "ME_pred = []\n",
    "\n",
    "\n",
    "FN_label = []\n",
    "FN_dVertex = []\n",
    "FN_dT = []\n",
    "FN_vertexX = []\n",
    "FN_vertexY = []\n",
    "FN_vertexZ = []\n",
    "FN_pred = []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if labels[i] == 1:\n",
    "        ME_label.append(labels[i])\n",
    "        ME_dVertex.append(dVertexs[i])\n",
    "        ME_dT.append(dTs[i])\n",
    "        ME_vertexX.append(vertexXs[i])\n",
    "        ME_vertexY.append(vertexYs[i])\n",
    "        ME_vertexZ.append(vertexZs[i])\n",
    "        ME_pred.append(preds[i])\n",
    "    else:\n",
    "   \n",
    "        FN_label.append(labels[i])\n",
    "        FN_dVertex.append(dVertexs[i])\n",
    "        FN_dT.append(dTs[i])\n",
    "        FN_vertexX.append(vertexXs[i])\n",
    "        FN_vertexY.append(vertexYs[i])\n",
    "        FN_vertexZ.append(vertexZs[i])\n",
    "        FN_pred.append(preds[i])\n",
    "        \n",
    "ME_sig = -np.log((1/np.array(ME_pred))-1)\n",
    "FN_sig = -np.log((1/np.array(FN_pred))-1)\n",
    "FN_over_0 = 100*np.sum(FN_sig > 0)/len(FN_sig)\n",
    "ME_under_0 = 100*np.sum(ME_sig < 0)/len(ME_sig)\n",
    "\n",
    "\n",
    "##################plot CNN score distribution figure\n",
    "plt.hist(FN_sig, bins = 100, range = (-20, 20), density = True, color ='r',histtype = 'step')\n",
    "plt.hist(ME_sig, bins = 100, range = (-20, 20), density = True, color ='b',histtype = 'step')\n",
    "# plt.text(10, 0.15,'FN > 0' + str(FN_over_0), fontsize = 20)\n",
    "# plt.text(10, 0.1, 'ME < 0' + str(ME_under_0), fontsize = 20)\n",
    "\n",
    "\n",
    "FN_over = '%.2f' %FN_over_0\n",
    "ME_under = '%.2f' %ME_under_0\n",
    "\n",
    "label = ['FN : FN > 0 = '+FN_over+'%', \n",
    "         'ME : ME < 0 = '+ME_under+'%']\n",
    "\n",
    "\n",
    "leg = plt.legend(label, loc = 'best', frameon=False)\n",
    "\n",
    "leg_lines = leg.get_lines()\n",
    "leg_texts = leg.get_texts()\n",
    "\n",
    "plt.setp(leg_lines, linewidth=15)\n",
    "plt.setp(leg_texts, fontsize=15)\n",
    "\n",
    "plt.title('')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "num_FN = len(FN_dT)\n",
    "num_ME = len(ME_dT)\n",
    "###########plot dT\n",
    "plt.hist(np.array(FN_dT)*0.001, bins = 100, color= 'r', alpha = 0.5, density = True, histtype = 'step')\n",
    "plt.hist(np.array(ME_dT)*0.001, bins = 100, color= 'b', alpha = 0.5, density = True, histtype = 'step')\n",
    "\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.xlabel(\"\\u03BCs\", fontsize=15, loc='right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###########plot dVertex\n",
    "plt.hist(np.array(FN_dVertex)*100, bins = 80, color= 'r', alpha = 0.5, density = True, histtype = 'step')\n",
    "plt.hist(np.array(ME_dVertex)*100, bins = 80, color= 'b', alpha = 0.5, density = True, histtype = 'step')\n",
    "\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.xlabel(\"cm\", fontsize=15, loc='right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "##############plot vertexZ\n",
    "plt.hist(np.array(FN_vertexZ)*100, bins = 80, color= 'r', alpha = 0.5, density = True, histtype = 'step')\n",
    "plt.hist(np.array(ME_vertexZ)*100, bins = 80, color= 'b', alpha = 0.5, density = True, histtype = 'step')\n",
    "\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.xlabel(\"cm\", fontsize=15, loc='right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##############plot R2\n",
    "plt.hist((np.array(FN_vertexX)**2+np.array(FN_vertexY)**2)*100, bins = 80, color= 'r', alpha = 0.5, density = True, histtype = 'step')\n",
    "plt.hist((np.array(ME_vertexX)**2+np.array(ME_vertexY)**2)*100, bins = 80, color= 'b', alpha = 0.5, density = True, histtype = 'step')\n",
    "\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.xlabel(\"cm\", fontsize=15, loc='right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "list_range = np.arange(0,1,0.001)\n",
    "\n",
    "\n",
    "for i in range(len(list_range)):\n",
    "    a = len(np.array(ME_pred)[np.array(ME_pred)>list_range[i]])/len(np.array(ME_pred))\n",
    "#     print(list_range[i])\n",
    "    \n",
    "    if (a > 0.99):\n",
    "     \n",
    "        eff_99 = list_range[i]\n",
    "        continue\n",
    "        \n",
    "    if (a > 0.95):\n",
    "        \n",
    "        eff_95 = list_range[i]\n",
    "        continue\n",
    "        \n",
    "    if (a > 0.90):\n",
    "       \n",
    "        eff_90 = list_range[i]\n",
    "        continue\n",
    "##### eff 0.5 pred\n",
    "eff_50_ME = len(np.array(ME_pred)[np.array(ME_pred)>0.5])/len(np.array(ME_pred))\n",
    "eff_50_FN = len(np.array(FN_pred)[np.array(FN_pred)>0.5])/len(np.array(FN_pred))\n",
    "num_50_ME = num_ME*len(np.array(ME_pred)[np.array(ME_pred)>0.5])/len(np.array(ME_pred))\n",
    "num_50_FN = num_FN*len(np.array(FN_pred)[np.array(FN_pred)>0.5])/len(np.array(FN_pred))\n",
    "\n",
    "\n",
    "\n",
    "##### eff 99% efficient\n",
    "eff_99_ME = len(np.array(ME_pred)[np.array(ME_pred)>eff_99])/len(np.array(ME_pred))\n",
    "eff_99_FN = len(np.array(FN_pred)[np.array(FN_pred)>eff_99])/len(np.array(FN_pred))\n",
    "num_99_ME = num_ME*len(np.array(ME_pred)[np.array(ME_pred)>eff_99])/len(np.array(ME_pred))\n",
    "num_99_FN = num_FN*len(np.array(FN_pred)[np.array(FN_pred)>eff_99])/len(np.array(FN_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### eff 95% efficient\n",
    "eff_95_ME = len(np.array(ME_pred)[np.array(ME_pred)>eff_95])/len(np.array(ME_pred))\n",
    "eff_95_FN = len(np.array(FN_pred)[np.array(FN_pred)>eff_95])/len(np.array(FN_pred))\n",
    "num_95_ME = num_ME*len(np.array(ME_pred)[np.array(ME_pred)>eff_95])/len(np.array(ME_pred))\n",
    "num_95_FN = num_FN*len(np.array(FN_pred)[np.array(FN_pred)>eff_95])/len(np.array(FN_pred))\n",
    "\n",
    "\n",
    "##### eff 90% efficient\n",
    "eff_90_ME = len(np.array(ME_pred)[np.array(ME_pred)>eff_90])/len(np.array(ME_pred))\n",
    "eff_90_FN = len(np.array(FN_pred)[np.array(FN_pred)>eff_90])/len(np.array(FN_pred))\n",
    "num_90_ME = num_ME*len(np.array(ME_pred)[np.array(ME_pred)>eff_90])/len(np.array(ME_pred))\n",
    "num_90_FN = num_FN*len(np.array(FN_pred)[np.array(FN_pred)>eff_90])/len(np.array(FN_pred))\n",
    "\n",
    "\n",
    " \n",
    "# # f = open('result/' + args.output + '/' + args.output + '_efficiency.txt','w')\n",
    "# print('         |   90%   |   95%   |   99%   |   mid   |',file=f)\n",
    "# print('--------------------------------------------------',file=f)\n",
    "# print('  ME_eff |','%.4f  |'%eff_90_ME,'%.4f  |'%eff_95_ME,'%.4f  |'%eff_99_ME,'%.4f  |'%eff_50_ME,file=f)\n",
    "# print('--------------------------------------------------',file=f)\n",
    "# print('  FN_eff |','%.4f  |'%eff_90_FN,'%.4f  |'%eff_95_FN,'%.4f  |'%eff_99_FN,'%.4f  |'%eff_50_FN,file=f)\n",
    "# print('--------------------------------------------------',file=f)\n",
    "# print('ME_remain|','%7d'%int(num_90_ME),'|','%7d'%int(num_95_ME),'|','%7d'%int(num_99_ME),'|','%7d'%int(num_50_ME),'|',file=f)\n",
    "# print('--------------------------------------------------',file=f)\n",
    "# print('FN_remain|','%7d'%int(num_90_FN),'|','%7d'%int(num_95_FN),'|','%7d'%int(num_99_FN),'|','%7d'%int(num_50_FN),'|',file=f)\n",
    "# print('--------------------------------------------------',file=f)\n",
    "# print('CNN score|','','%.3f'%eff_90,' | ','%.3f'%eff_95,' | ','%.3f'%eff_99,' |  ',0.5,'  |',file=f)\n",
    "# print('==================================================',file=f)\n",
    "# print('         |   FN    |   ME    |',file=f)\n",
    "# print('# data   |','%7d'%len(FN_dT),'|', '%7d'%len(ME_dT),'|',file=f)\n",
    "\n",
    "# f.close()\n",
    "\n",
    "\n",
    "\n",
    "###############plot evaluation \n",
    "\n",
    "##### Draw ROC curve #####\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from matplotlib.cbook import get_sample_data\n",
    "\n",
    "df = pd.read_csv(fPred)\n",
    "tpr, fpr, thr = roc_curve(df['label'], df['prediction'], sample_weight=df['weight'], pos_label=0)\n",
    "auc = roc_auc_score(df['label'], df['prediction'], sample_weight=df['weight'])\n",
    "\n",
    "\n",
    "df_bkg = df[df.label==0]\n",
    "df_sig = df[df.label==1]\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "\n",
    "plt.hist(df_bkg['prediction']*100, weights=df_bkg['weight'], histtype='step', \n",
    "         density=True, bins=50, color='red', linewidth=3)\n",
    "\n",
    "plt.hist(df_sig['prediction']*100, weights=df_sig['weight'], histtype='step', \n",
    "         density=True, bins=50, color='blue', linewidth=3)\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(0, 101, step=20),[\"{}\".format(x*0.01) for x in np.arange(0, 101,step=20)],fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xlabel(\"CNN score\", fontsize=35, loc='right')\n",
    "plt.ylabel(\"Normalized\", fontsize=35, loc='top')\n",
    "plt.xlim(0, 100)\n",
    "label = ['Fast Neutron', 'Michel Electrons']\n",
    "\n",
    "leg = plt.legend(label, loc = 'upper center', frameon=False)\n",
    "\n",
    "leg_lines = leg.get_lines()\n",
    "leg_texts = leg.get_texts()\n",
    "\n",
    "plt.setp(leg_lines, linewidth=30)\n",
    "plt.setp(leg_texts, fontsize=30)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################### plot AUC\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(fpr*100, tpr*100, label='AUC = %.3f' % (auc))\n",
    "plt.plot(eff_99_FN*100, eff_99_ME*100,'*r', markersize=40)\n",
    "\n",
    "plt.plot(eff_95_FN*100, eff_95_ME*100,'*g', markersize=40)\n",
    "\n",
    "plt.plot(eff_90_FN*100, eff_90_ME*100,'*b', markersize=40)\n",
    "\n",
    "plt.plot(eff_50_FN*100, eff_50_ME*100,'*k', markersize=40)\n",
    "\n",
    "plt.xlabel('FN efficiency (%)', fontsize=35, loc='right')\n",
    "plt.ylabel('ME efficiency (%)', fontsize=35, loc='top')\n",
    "\n",
    "\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.grid()\n",
    "print_auc = '%.3f' %auc\n",
    "print_eff_99 = '%.3f' %eff_99\n",
    "print_eff_95 = '%.3f' %eff_95\n",
    "print_eff_90 = '%.3f' %eff_90\n",
    "label = ['AUC = '+print_auc,'99% WP(score='+print_eff_99+')', '95% WP(score='+print_eff_95+')', '90% WP(score='+print_eff_90+')','Middle WP (score=0.5)']\n",
    "\n",
    "leg = plt.legend(label, loc = 'right', frameon=False)\n",
    "\n",
    " \n",
    "leg_lines = leg.get_lines()\n",
    "leg_texts = leg.get_texts()\n",
    "\n",
    "plt.setp(leg_lines, linewidth=15)\n",
    "plt.setp(leg_texts, fontsize=30)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(nEpoch):\n",
    "\n",
    "\n",
    "    for i, (data, label0, weight, rescale, procIdx, fileIdx, idx, dVertexx, minvaluee, pChargee,vertexx,vertexy,vertexz) in enumerate(tqdm(testLoader, desc='epoch %d/%d' % (epoch+1, nEpoch))):\n",
    "        data = data.to(device)\n",
    "        label = label0.float().to(device)\n",
    "        weight = (weight*rescale).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(\"cpu\")\n",
    "label = label.to(\"cpu\")\n",
    "data_avg =np.average(data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg[label==0],axis=0).T,color='red',label='FN')\n",
    "plt.plot(np.average(data_avg[label==1],axis=0).T,color='blue',label='ME')\n",
    "plt.plot(np.average(data_avg[label==1],axis=0).T-np.average(data_avg[label==0],axis=0).T,color='green',label='dif')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"config\" : 'config_even_eval.yaml',\n",
    "    \"output\" : 'test_220330',\n",
    "  \n",
    "    \"device\" : 0,\n",
    "    \"epoch\" : 1,\n",
    "    \"batch\" : 10000000,\n",
    "    \"lr\" : 0.0001,\n",
    "    \"seed\" : 12345,\n",
    "    \"kernel_size\" : 11,\n",
    "    \"model\" : '1DCNN3FC2',\n",
    "    \"ratio\" : 1.0,\n",
    "    \"runnum\" : 1563,\n",
    "    \"rho\" : 1.6,\n",
    "    \"vtz\" : 1.0,\n",
    "    \"odd\" : 1,\n",
    "    \"minvalue\" : 400,\n",
    "    \"dvertex\" : 1,\n",
    "  \n",
    "   \n",
    "\n",
    "})\n",
    "\n",
    "config = yaml.load(open(args.config).read(), Loader=yaml.FullLoader)\n",
    "config['training']['learningRate'] = float(config['training']['learningRate'])\n",
    "if args.seed: config['training']['randomSeed1'] = args.seed\n",
    "if args.epoch: config['training']['epoch'] = args.epoch\n",
    "if args.lr: config['training']['learningRate'] = args.lr\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "if torch.cuda.is_available() and args.device >= 0: torch.cuda.set_device(args.device)\n",
    "if not os.path.exists('result/' + args.output): os.makedirs('result/' + args.output)\n",
    "\n",
    "##### Define dataset instance #####\n",
    "from dataset.WFCh2Dataset_each_norm_involve_raw import *\n",
    "\n",
    "##### Define dataset instance #####\n",
    "dset = WFCh2Dataset_each_norm_involve_raw(channel=config['format']['channel'], output = 'result/' + args.output)\n",
    "for sampleInfo in config['samples']:\n",
    "    if 'ignore' in sampleInfo and sampleInfo['ignore']: continue\n",
    "    name = sampleInfo['name']\n",
    "    if args.odd == 1:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_even_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    elif args.odd == 2:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_odd_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    \n",
    "    else: ## total training\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    print(in_path)\n",
    "\n",
    "    dset.addSample(name, in_path, weight=sampleInfo['xsec']/sampleInfo['ngen'])\n",
    "    dset.setProcessLabel(name, sampleInfo['label'])\n",
    "dset.initialize()\n",
    "\n",
    "lengths = [int(x*len(dset)) for x in config['training']['splitFractions']]\n",
    "lengths.append(len(dset)-sum(lengths))\n",
    "torch.manual_seed(config['training']['randomSeed1'])\n",
    "kwargs = {'num_workers':min(config['training']['nDataLoaders'], os.cpu_count()),\n",
    "          'batch_size':args.batch, 'pin_memory':False}\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "testLoader = DataLoader(dset, **kwargs)\n",
    "\n",
    "\n",
    "torch.manual_seed(torch.initial_seed())\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "bestState, bestLoss = {}, 1e9\n",
    "train = {'loss':[], 'acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "nEpoch = config['training']['epoch']\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(nEpoch):\n",
    "\n",
    "\n",
    "    for i, (data, label0, weight, rescale, procIdx, fileIdx, idx, dVertexx, minvaluee, pChargee,vertexx,vertexy,vertexz) in enumerate(tqdm(testLoader, desc='epoch %d/%d' % (epoch+1, nEpoch))):\n",
    "        data_16 = data.to(device)\n",
    "        label_16 = label0.float().to(device)\n",
    "        weight_16 = (weight*rescale).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_16 = data_16.to(\"cpu\")\n",
    "label_16 = label_16.to(\"cpu\")\n",
    "data_avg_16 =np.average(data_16,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg_16[label_16==0],axis=0).T,color='red',label='FN')\n",
    "plt.plot(np.average(data_avg_16[label_16==1],axis=0).T,color='blue',label='ME')\n",
    "plt.plot(np.average(data_avg_16[label_16==1],axis=0).T-np.average(data_avg_16[label_16==0],axis=0).T,color='green',label='dif')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"config\" : 'config_even_eval.yaml',\n",
    "    \"output\" : 'test_220330',\n",
    "  \n",
    "    \"device\" : 0,\n",
    "    \"epoch\" : 1,\n",
    "    \"batch\" : 10000000,\n",
    "    \"lr\" : 0.0001,\n",
    "    \"seed\" : 12345,\n",
    "    \"kernel_size\" : 11,\n",
    "    \"model\" : '1DCNN3FC2',\n",
    "    \"ratio\" : 1.0,\n",
    "    \"runnum\" : 1563,\n",
    "    \"rho\" : 1.8,\n",
    "    \"vtz\" : 1.0,\n",
    "    \"odd\" : 1,\n",
    "    \"minvalue\" : 400,\n",
    "    \"dvertex\" : 1,\n",
    "  \n",
    "   \n",
    "\n",
    "})\n",
    "\n",
    "config = yaml.load(open(args.config).read(), Loader=yaml.FullLoader)\n",
    "config['training']['learningRate'] = float(config['training']['learningRate'])\n",
    "if args.seed: config['training']['randomSeed1'] = args.seed\n",
    "if args.epoch: config['training']['epoch'] = args.epoch\n",
    "if args.lr: config['training']['learningRate'] = args.lr\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "if torch.cuda.is_available() and args.device >= 0: torch.cuda.set_device(args.device)\n",
    "if not os.path.exists('result/' + args.output): os.makedirs('result/' + args.output)\n",
    "\n",
    "##### Define dataset instance #####\n",
    "from dataset.WFCh2Dataset_each_norm_involve_raw import *\n",
    "\n",
    "##### Define dataset instance #####\n",
    "dset = WFCh2Dataset_each_norm_involve_raw(channel=config['format']['channel'], output = 'result/' + args.output)\n",
    "for sampleInfo in config['samples']:\n",
    "    if 'ignore' in sampleInfo and sampleInfo['ignore']: continue\n",
    "    name = sampleInfo['name']\n",
    "    if args.odd == 1:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_even_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    elif args.odd == 2:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_odd_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    \n",
    "    else: ## total training\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    print(in_path)\n",
    "\n",
    "    dset.addSample(name, in_path, weight=sampleInfo['xsec']/sampleInfo['ngen'])\n",
    "    dset.setProcessLabel(name, sampleInfo['label'])\n",
    "dset.initialize()\n",
    "\n",
    "lengths = [int(x*len(dset)) for x in config['training']['splitFractions']]\n",
    "lengths.append(len(dset)-sum(lengths))\n",
    "torch.manual_seed(config['training']['randomSeed1'])\n",
    "kwargs = {'num_workers':min(config['training']['nDataLoaders'], os.cpu_count()),\n",
    "          'batch_size':args.batch, 'pin_memory':False}\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "testLoader = DataLoader(dset, **kwargs)\n",
    "\n",
    "\n",
    "torch.manual_seed(torch.initial_seed())\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "bestState, bestLoss = {}, 1e9\n",
    "train = {'loss':[], 'acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "nEpoch = config['training']['epoch']\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(nEpoch):\n",
    "\n",
    "\n",
    "    for i, (data, label0, weight, rescale, procIdx, fileIdx, idx, dVertexx, minvaluee, pChargee,vertexx,vertexy,vertexz) in enumerate(tqdm(testLoader, desc='epoch %d/%d' % (epoch+1, nEpoch))):\n",
    "        data_18 = data.to(device)\n",
    "        label_18 = label0.float().to(device)\n",
    "        weight_18 = (weight*rescale).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_18 = data_18.to(\"cpu\")\n",
    "label_18 = label_18.to(\"cpu\")\n",
    "data_avg_18 =np.average(data_18,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg_18[label_18==0],axis=0).T,color='red',label='FN')\n",
    "plt.plot(np.average(data_avg_18[label_18==1],axis=0).T,color='blue',label='ME')\n",
    "plt.plot(np.average(data_avg_18[label_18==1],axis=0).T-np.average(data_avg_18[label_18==0],axis=0).T,color='green',label='dif')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg[label==1],axis=0).T,color='red',label='ME_DIN')\n",
    "\n",
    "plt.plot(np.average(data_avg_16[label_16==1],axis=0).T,color='blue',label='ME_nonDIN candidate')\n",
    "\n",
    "plt.plot(np.average(data_avg_18[label_18==1],axis=0).T,color='green',label='ME_noDIN')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg[label==0],axis=0).T,color='red',label='FN_DIN')\n",
    "\n",
    "plt.plot(np.average(data_avg_16[label_16==0],axis=0).T,color='blue',label='FN_nonDIN candidate')\n",
    "\n",
    "plt.plot(np.average(data_avg_18[label_18==0],axis=0).T,color='green',label='FN_noDIN')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg[label==1],axis=0).T/max(np.average(data_avg[label==1],axis=0)),color='red',label='ME_DIN')\n",
    "\n",
    "plt.plot(np.average(data_avg_16[label_16==1],axis=0).T/max(np.average(data_avg_16[label_16==1],axis=0)),color='blue',label='ME_nonDIN candidate')\n",
    "\n",
    "plt.plot(np.average(data_avg_18[label_18==1],axis=0).T/max(np.average(data_avg_18[label_18==1],axis=0)),color='green',label='ME_noDIN')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg[label==0],axis=0).T/max(np.average(data_avg[label==0],axis=0)),color='red',label='FN_DIN')\n",
    "\n",
    "plt.plot(np.average(data_avg_16[label_16==0],axis=0).T/max(np.average(data_avg_16[label_16==0],axis=0)),color='blue',label='FN_nonDIN candidate')\n",
    "\n",
    "plt.plot(np.average(data_avg_18[label_18==0],axis=0).T/max(np.average(data_avg_18[label_18==0],axis=0)),color='green',label='FN_noDIN')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"config\" : 'config_total.yaml',\n",
    "    \"output\" : 'test_220330',\n",
    "  \n",
    "    \"device\" : 0,\n",
    "    \"epoch\" : 1,\n",
    "    \"batch\" : 10000000,\n",
    "    \"lr\" : 0.0001,\n",
    "    \"seed\" : 12345,\n",
    "    \"kernel_size\" : 11,\n",
    "    \"model\" : '1DCNN3FC2',\n",
    "    \"ratio\" : 1.0,\n",
    "    \"runnum\" : 1500,\n",
    "    \"rho\" : 1.4,\n",
    "    \"vtz\" : 1.0,\n",
    "    \"odd\" : 1,\n",
    "    \"minvalue\" : 400,\n",
    "    \"dvertex\" : 1,\n",
    "  \n",
    "   \n",
    "\n",
    "})\n",
    "\n",
    "config = yaml.load(open(args.config).read(), Loader=yaml.FullLoader)\n",
    "config['training']['learningRate'] = float(config['training']['learningRate'])\n",
    "if args.seed: config['training']['randomSeed1'] = args.seed\n",
    "if args.epoch: config['training']['epoch'] = args.epoch\n",
    "if args.lr: config['training']['learningRate'] = args.lr\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "if torch.cuda.is_available() and args.device >= 0: torch.cuda.set_device(args.device)\n",
    "if not os.path.exists('result/' + args.output): os.makedirs('result/' + args.output)\n",
    "\n",
    "##### Define dataset instance #####\n",
    "from dataset.WFCh2Dataset_each_norm_involve_raw import *\n",
    "\n",
    "##### Define dataset instance #####\n",
    "dset = WFCh2Dataset_each_norm_involve_raw(channel=config['format']['channel'], output = 'result/' + args.output)\n",
    "for sampleInfo in config['samples']:\n",
    "    if 'ignore' in sampleInfo and sampleInfo['ignore']: continue\n",
    "    name = sampleInfo['name']\n",
    "    if args.odd == 1:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_even_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    elif args.odd == 2:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_odd_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    \n",
    "    else: ## total training\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    print(in_path)\n",
    "\n",
    "    dset.addSample(name, in_path, weight=sampleInfo['xsec']/sampleInfo['ngen'])\n",
    "    dset.setProcessLabel(name, sampleInfo['label'])\n",
    "dset.initialize()\n",
    "\n",
    "lengths = [int(x*len(dset)) for x in config['training']['splitFractions']]\n",
    "lengths.append(len(dset)-sum(lengths))\n",
    "torch.manual_seed(config['training']['randomSeed1'])\n",
    "kwargs = {'num_workers':min(config['training']['nDataLoaders'], os.cpu_count()),\n",
    "          'batch_size':args.batch, 'pin_memory':False}\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "testLoader = DataLoader(dset, **kwargs)\n",
    "\n",
    "\n",
    "torch.manual_seed(torch.initial_seed())\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "bestState, bestLoss = {}, 1e9\n",
    "train = {'loss':[], 'acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "nEpoch = config['training']['epoch']\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(nEpoch):\n",
    "\n",
    "\n",
    "    for i, (data, label0, weight, rescale, procIdx, fileIdx, idx, dVertexx, minvaluee, pChargee,vertexx,vertexy,vertexz) in enumerate(tqdm(testLoader, desc='epoch %d/%d' % (epoch+1, nEpoch))):\n",
    "        data_1500 = data.to(device)\n",
    "        label_1500 = label0.float().to(device)\n",
    "        weight_1500 = (weight*rescale).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1500 = data_1500.to(\"cpu\")\n",
    "label_1500 = label_1500.to(\"cpu\")\n",
    "data_avg_1500 =np.average(data_1500,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg_1500[label_1500==0],axis=0).T,color='red',label='FN')\n",
    "plt.plot(np.average(data_avg_1500[label_1500==1],axis=0).T,color='blue',label='ME')\n",
    "plt.plot(np.average(data_avg_1500[label_1500==1],axis=0).T-np.average(data_avg_1500[label_1500==0],axis=0).T,color='green',label='dif')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"config\" : 'config_total.yaml',\n",
    "    \"output\" : 'test_220330',\n",
    "  \n",
    "    \"device\" : 0,\n",
    "    \"epoch\" : 1,\n",
    "    \"batch\" : 10000000,\n",
    "    \"lr\" : 0.0001,\n",
    "    \"seed\" : 12345,\n",
    "    \"kernel_size\" : 11,\n",
    "    \"model\" : '1DCNN3FC2',\n",
    "    \"ratio\" : 1.0,\n",
    "    \"runnum\" : 1500,\n",
    "    \"rho\" : 1.6,\n",
    "    \"vtz\" : 1.0,\n",
    "    \"odd\" : 1,\n",
    "    \"minvalue\" : 400,\n",
    "    \"dvertex\" : 1,\n",
    "  \n",
    "   \n",
    "\n",
    "})\n",
    "\n",
    "config = yaml.load(open(args.config).read(), Loader=yaml.FullLoader)\n",
    "config['training']['learningRate'] = float(config['training']['learningRate'])\n",
    "if args.seed: config['training']['randomSeed1'] = args.seed\n",
    "if args.epoch: config['training']['epoch'] = args.epoch\n",
    "if args.lr: config['training']['learningRate'] = args.lr\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "if torch.cuda.is_available() and args.device >= 0: torch.cuda.set_device(args.device)\n",
    "if not os.path.exists('result/' + args.output): os.makedirs('result/' + args.output)\n",
    "\n",
    "##### Define dataset instance #####\n",
    "from dataset.WFCh2Dataset_each_norm_involve_raw import *\n",
    "\n",
    "##### Define dataset instance #####\n",
    "dset = WFCh2Dataset_each_norm_involve_raw(channel=config['format']['channel'], output = 'result/' + args.output)\n",
    "for sampleInfo in config['samples']:\n",
    "    if 'ignore' in sampleInfo and sampleInfo['ignore']: continue\n",
    "    name = sampleInfo['name']\n",
    "    if args.odd == 1:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_even_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    elif args.odd == 2:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_odd_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    \n",
    "    else: ## total training\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    print(in_path)\n",
    "\n",
    "    dset.addSample(name, in_path, weight=sampleInfo['xsec']/sampleInfo['ngen'])\n",
    "    dset.setProcessLabel(name, sampleInfo['label'])\n",
    "dset.initialize()\n",
    "\n",
    "lengths = [int(x*len(dset)) for x in config['training']['splitFractions']]\n",
    "lengths.append(len(dset)-sum(lengths))\n",
    "torch.manual_seed(config['training']['randomSeed1'])\n",
    "kwargs = {'num_workers':min(config['training']['nDataLoaders'], os.cpu_count()),\n",
    "          'batch_size':args.batch, 'pin_memory':False}\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "testLoader = DataLoader(dset, **kwargs)\n",
    "\n",
    "\n",
    "torch.manual_seed(torch.initial_seed())\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "bestState, bestLoss = {}, 1e9\n",
    "train = {'loss':[], 'acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "nEpoch = config['training']['epoch']\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(nEpoch):\n",
    "\n",
    "\n",
    "    for i, (data, label0, weight, rescale, procIdx, fileIdx, idx, dVertexx, minvaluee, pChargee,vertexx,vertexy,vertexz) in enumerate(tqdm(testLoader, desc='epoch %d/%d' % (epoch+1, nEpoch))):\n",
    "        data_1500_16 = data.to(device)\n",
    "        label_1500_16 = label0.float().to(device)\n",
    "        weight_1500_16 = (weight*rescale).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1500_16 = data_1500_16.to(\"cpu\")\n",
    "label_1500_16 = label_1500_16.to(\"cpu\")\n",
    "data_avg_1500_16 =np.average(data_1500_16,axis=1)\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_16[label_1500_16==0],axis=0).T,color='red',label='FN')\n",
    "plt.plot(np.average(data_avg_1500_16[label_1500_16==1],axis=0).T,color='blue',label='ME')\n",
    "plt.plot(np.average(data_avg_1500_16[label_1500_16==1],axis=0).T-np.average(data_avg_1500_16[label_1500_16==0],axis=0).T,color='green',label='dif')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"config\" : 'config_total.yaml',\n",
    "    \"output\" : 'test_220330',\n",
    "  \n",
    "    \"device\" : 0,\n",
    "    \"epoch\" : 1,\n",
    "    \"batch\" : 10000000,\n",
    "    \"lr\" : 0.0001,\n",
    "    \"seed\" : 12345,\n",
    "    \"kernel_size\" : 11,\n",
    "    \"model\" : '1DCNN3FC2',\n",
    "    \"ratio\" : 1.0,\n",
    "    \"runnum\" : 1500,\n",
    "    \"rho\" : 1.8,\n",
    "    \"vtz\" : 1.0,\n",
    "    \"odd\" : 1,\n",
    "    \"minvalue\" : 400,\n",
    "    \"dvertex\" : 1,\n",
    "  \n",
    "   \n",
    "\n",
    "})\n",
    "\n",
    "config = yaml.load(open(args.config).read(), Loader=yaml.FullLoader)\n",
    "config['training']['learningRate'] = float(config['training']['learningRate'])\n",
    "if args.seed: config['training']['randomSeed1'] = args.seed\n",
    "if args.epoch: config['training']['epoch'] = args.epoch\n",
    "if args.lr: config['training']['learningRate'] = args.lr\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "if torch.cuda.is_available() and args.device >= 0: torch.cuda.set_device(args.device)\n",
    "if not os.path.exists('result/' + args.output): os.makedirs('result/' + args.output)\n",
    "\n",
    "##### Define dataset instance #####\n",
    "from dataset.WFCh2Dataset_each_norm_involve_raw import *\n",
    "\n",
    "##### Define dataset instance #####\n",
    "dset = WFCh2Dataset_each_norm_involve_raw(channel=config['format']['channel'], output = 'result/' + args.output)\n",
    "for sampleInfo in config['samples']:\n",
    "    if 'ignore' in sampleInfo and sampleInfo['ignore']: continue\n",
    "    name = sampleInfo['name']\n",
    "    if args.odd == 1:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_even_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    elif args.odd == 2:\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_odd_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    \n",
    "    else: ## total training\n",
    "        in_path = '/store/hep/users/yewzzang/JSNS2/com_data/r00'+str(args.runnum)+'/'+name+'_cut_Rho_'+str(args.rho)+'_ZL_'+str(args.vtz)+'/*.h5'\n",
    "    print(in_path)\n",
    "\n",
    "    dset.addSample(name, in_path, weight=sampleInfo['xsec']/sampleInfo['ngen'])\n",
    "    dset.setProcessLabel(name, sampleInfo['label'])\n",
    "dset.initialize()\n",
    "\n",
    "lengths = [int(x*len(dset)) for x in config['training']['splitFractions']]\n",
    "lengths.append(len(dset)-sum(lengths))\n",
    "torch.manual_seed(config['training']['randomSeed1'])\n",
    "kwargs = {'num_workers':min(config['training']['nDataLoaders'], os.cpu_count()),\n",
    "          'batch_size':args.batch, 'pin_memory':False}\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "testLoader = DataLoader(dset, **kwargs)\n",
    "\n",
    "\n",
    "torch.manual_seed(torch.initial_seed())\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "bestState, bestLoss = {}, 1e9\n",
    "train = {'loss':[], 'acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "nEpoch = config['training']['epoch']\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(nEpoch):\n",
    "\n",
    "\n",
    "    for i, (data, label0, weight, rescale, procIdx, fileIdx, idx, dVertexx, minvaluee, pChargee,vertexx,vertexy,vertexz) in enumerate(tqdm(testLoader, desc='epoch %d/%d' % (epoch+1, nEpoch))):\n",
    "        data_1500_18 = data.to(device)\n",
    "        label_1500_18 = label0.float().to(device)\n",
    "        weight_1500_18 = (weight*rescale).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1500_18 = data_1500_18.to(\"cpu\")\n",
    "label_1500_18 = label_1500_18.to(\"cpu\")\n",
    "data_avg_1500_18 =np.average(data_1500_18,axis=1)\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_18[label_1500_18==0],axis=0).T,color='red',label='FN')\n",
    "plt.plot(np.average(data_avg_1500_18[label_1500_18==1],axis=0).T,color='blue',label='ME')\n",
    "plt.plot(np.average(data_avg_1500_18[label_1500_18==1],axis=0).T-np.average(data_avg_1500_18[label_1500_18==0],axis=0).T,color='green',label='dif')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg_1500[label_1500==1],axis=0).T,color='red',label='ME_1.4')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_16[label_1500_16==1],axis=0).T,color='blue',label='ME_1.4-1.6')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_18[label_1500_18==1],axis=0).T,color='green',label='ME_1.6-1.8')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg_1500[label_1500==0],axis=0).T,color='red',label='FN_1.4')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_16[label_1500_16==0],axis=0).T,color='blue',label='FN_1.4-1.6')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_18[label_1500_18==0],axis=0).T,color='green',label='FN_1.6-1.8')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg_1500[label_1500==1],axis=0).T/max(np.average(data_avg_1500[label_1500==1],axis=0)),color='red',label='ME_1.4')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_16[label_1500_16==1],axis=0).T/max(np.average(data_avg_1500_16[label_1500_16==1],axis=0)),color='blue',label='ME_1.4-1.6')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_18[label_1500_18==1],axis=0).T/max(np.average(data_avg_1500_18[label_1500_18==1],axis=0)),color='green',label='ME_1.6-1.8')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg_1500[label_1500==0],axis=0).T/max(np.average(data_avg_1500[label_1500==0],axis=0)),color='red',label='FN_1.4')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_16[label_1500_16==0],axis=0).T/max(np.average(data_avg_1500_16[label_1500_16==0],axis=0)),color='blue',label='FN_1.4-1.6')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_18[label_1500_18==0],axis=0).T/max(np.average(data_avg_1500_18[label_1500_18==0],axis=0)),color='green',label='FN_1.6-1.8')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg_1500[label_1500==1],axis=0).T-np.average(data_avg[label==1],axis=0).T,color='red',label='noDIN-DIN ME_1.4')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_16[label_1500_16==1],axis=0).T-np.average(data_avg_16[label_16==1],axis=0).T,color='blue',label='noDIN-DIN ME_1.4-1.6')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_18[label_1500_18==1],axis=0).T-np.average(data_avg_18[label_18==1],axis=0).T,color='green',label='noDIN-DIN ME_1.6-1.8')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.average(data_avg_1500[label_1500==0],axis=0).T-np.average(data_avg[label==0],axis=0).T,color='red',label='noDIN-DIN FN_1.4')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_16[label_1500_16==0],axis=0).T-np.average(data_avg_16[label_16==0],axis=0).T,color='blue',label='noDIN-DIN FN_1.4-1.6')\n",
    "\n",
    "plt.plot(np.average(data_avg_1500_18[label_1500_18==0],axis=0).T-np.average(data_avg_18[label_18==0],axis=0).T,color='green',label='noDIN-DIN FN_1.6-1.8')\n",
    "plt.plot(np.zeros(208),color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
